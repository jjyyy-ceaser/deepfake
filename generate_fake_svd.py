import torch
import os
import cv2
import numpy as np
from diffusers import StableVideoDiffusionPipeline
from diffusers.utils import export_to_video
from tqdm import tqdm

# ==========================================
# âš™ï¸ ì„¤ì • (ê³ í™”ì§ˆ ìœ ì§€)
# ==========================================
BASE_DIR = "C:/Users/leejy/Desktop/test_experiment/dataset"
REAL_VIDEO_DIR = os.path.join(BASE_DIR, "0_main_train", "real")
FAKE_VIDEO_DIR = os.path.join(BASE_DIR, "0_main_train", "fake")
TARGET_COUNT = 300

# âœ… í™”ì§ˆ íƒ€í˜‘ ì—†ìŒ! (XT ëª¨ë¸ ì‚¬ìš©)
MODEL_ID = "stabilityai/stable-video-diffusion-img2vid-xt"

print(f"ğŸ’ SVD ê³ í™”ì§ˆ ëª¨ë“œ (ë©”ëª¨ë¦¬ ìµœì í™” ì ìš©)")
os.makedirs(FAKE_VIDEO_DIR, exist_ok=True)

try:
    pipe = StableVideoDiffusionPipeline.from_pretrained(
        MODEL_ID, 
        torch_dtype=torch.float16, 
        variant="fp16"
    )
    
    # ğŸš¨ [í•µì‹¬ ìˆ˜ì •] ê°•ì œ GPU í• ë‹¹(pipe.to("cuda"))ì„ ëºë‹ˆë‹¤!
    # ëŒ€ì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì•Œì•„ì„œ ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•˜ê²Œ ë§¡ê¹ë‹ˆë‹¤.
    # ì´ë ‡ê²Œ í•˜ë©´ VRAMì´ ë¶€ì¡±í•´ë„ ëŠë ¤ì§€ì§€ ì•Šê³  íš¨ìœ¨ì ìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.
    pipe.enable_model_cpu_offload()
    
    # ì¶”ê°€ ë©”ëª¨ë¦¬ ìµœì í™” (í™”ì§ˆ ì˜í–¥ ì—†ìŒ)
    pipe.enable_attention_slicing()
    
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (CPU Offload + Slicing)")

except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: {e}")
    exit()

# ==========================================
# ğŸ¬ ìƒì„± ë£¨í”„
# ==========================================
real_videos = sorted([f for f in os.listdir(REAL_VIDEO_DIR) if f.endswith('.mp4')])
existing_fakes = [f for f in os.listdir(FAKE_VIDEO_DIR) if f.endswith('.mp4')]
current_count = len(existing_fakes)

print(f"ğŸ“Š í˜„ì¬ {current_count}ê°œ ì™„ë£Œ. {TARGET_COUNT}ê°œê¹Œì§€ ì§„í–‰í•©ë‹ˆë‹¤.")
pbar = tqdm(total=TARGET_COUNT, initial=current_count)

count = 0
for video_name in real_videos:
    if count >= TARGET_COUNT:
        break

    file_idx = count + 1
    save_filename = f"fake_svd_{file_idx:03d}.mp4"
    save_path = os.path.join(FAKE_VIDEO_DIR, save_filename)

    # ì´ë¯¸ ìˆìœ¼ë©´ íŒ¨ìŠ¤
    if os.path.exists(save_path) and os.path.getsize(save_path) > 0:
        count += 1
        continue

    try:
        video_path = os.path.join(REAL_VIDEO_DIR, video_name)
        cap = cv2.VideoCapture(video_path)
        ret, frame = cap.read()
        cap.release()
        
        if not ret:
            count += 1
            continue

        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        # í™”ì§ˆ ìœ ì§€ë¥¼ ìœ„í•´ í•´ìƒë„ ìœ ì§€ (1024x576)
        image = cv2.resize(frame, (1024, 576))
        from PIL import Image
        image = Image.fromarray(image)

        # ìƒì„± (Inference)
        # decode_chunk_size=2: ë§ˆì§€ë§‰ì— ë¹„ë””ì˜¤ í•©ì¹  ë•Œ VRAM í„°ì§€ëŠ” ê²ƒ ë°©ì§€
        frames = pipe(
            image, 
            decode_chunk_size=2, 
            num_inference_steps=25, # í™”ì§ˆì„ ìœ„í•´ 25ìŠ¤í… ìœ ì§€
            generator=torch.manual_seed(42)
        ).frames[0]

        export_to_video(frames, save_path, fps=7)
        
        pbar.update(1)
        pbar.set_description(f"Making {save_filename}")

    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬: {e}")
        # VRAM ë¶€ì¡± ë©”ì‹œì§€ê°€ ëœ¨ë©´ ì•Œë ¤ì¤Œ
        if "out of memory" in str(e).lower():
            print("ğŸš¨ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨(ìœ íŠœë¸Œ, í¬ë¡¬ ë“±)ì„ ë„ê³  ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
        break
    
    count += 1

pbar.close()
print("\nğŸ‰ ì™„ë£Œ!")