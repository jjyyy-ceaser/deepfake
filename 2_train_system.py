import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
import os
import json
import glob
import sys
from tqdm import tqdm  # ì§„í–‰ë°” ë¼ì´ë¸ŒëŸ¬ë¦¬
from utils import DeepfakeDataset, get_model
from torchvision import transforms

# =========================================================
# âš™ï¸ ì‹¤í—˜ ì„¤ì • (Configuration)
# =========================================================
# ìˆœì„œ: Pure(ê¸°ì¤€) -> Worst(ê·¹í•œ) -> Mixed(ë²”ìš©)
DATASETS = ["dataset_A_pure", "dataset_C_worst", "dataset_B_mixed"] 

# ì‚¬ìš©í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
MODELS = ["xception", "convnext", "swin", "r3d", "r2plus1d", "videomae_v2"]

# í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ë²”ìœ„
LR_LIST = [1e-4, 5e-5]
BATCH_LIST = [4, 8] # VideoMAEëŠ” ë©”ëª¨ë¦¬ ì´ìŠˆë¡œ ë‚´ë¶€ì—ì„œ [2, 4]ë¡œ ìë™ ì¡°ì •ë¨

# ì¥ì¹˜ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =========================================================
# ğŸ› ï¸ í•µì‹¬ í•¨ìˆ˜ ì •ì˜
# =========================================================

def get_data(dataset_name):
    """ë°ì´í„° íŒŒì¼ ê²½ë¡œì™€ ë¼ë²¨ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    base = os.path.join("dataset", "final_datasets", dataset_name)
    real = glob.glob(os.path.join(base, "real", "*"))
    fake = glob.glob(os.path.join(base, "fake", "*"))
    
    # ë°ì´í„° í™•ì¸
    if len(real) == 0 or len(fake) == 0:
        print(f"âš ï¸ ê²½ê³ : {dataset_name} í´ë”ê°€ ë¹„ì–´ìˆê±°ë‚˜ ê²½ë¡œê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return [], []

    files = real + fake
    labels = [0]*len(real) + [1]*len(fake)
    return files, labels

def train_epoch(model, loader, criterion, optimizer, is_mae, desc=""):
    """í•œ Epoch ë™ì•ˆ í•™ìŠµì„ ìˆ˜í–‰í•˜ë©° ì§„í–‰ë°”ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    model.train()
    running_loss = 0.0
    
    # tqdmìœ¼ë¡œ ë˜í•‘í•˜ì—¬ ì§„í–‰ë°” ìƒì„±
    loop = tqdm(loader, desc=desc, leave=False, file=sys.stdout)
    
    for x, y in loop:
        x, y = x.to(DEVICE), y.to(DEVICE)
        
        optimizer.zero_grad()
        
        # ëª¨ë¸ íƒ€ì…ì— ë”°ë¥¸ ìˆœì „íŒŒ(Forward)
        if is_mae: 
            # VideoMAEëŠ” ì…ë ¥ êµ¬ì¡°ê°€ ë‹¤ë¦„ (Batch, Time, Channel, Height, Width)
            out = model(pixel_values=x.permute(0,2,1,3,4)).logits
        else: 
            out = model(x)
            
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        
        # ì§„í–‰ë°” ì˜†ì— ì‹¤ì‹œê°„ Loss í‘œì‹œ
        loop.set_postfix(loss=f"{loss.item():.4f}")
    
    return running_loss / len(loader)

def evaluate(model, loader, is_mae):
    """ëª¨ë¸ ì„±ëŠ¥(AUC)ì„ í‰ê°€í•©ë‹ˆë‹¤."""
    model.eval()
    preds, trues = [], []
    
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            if is_mae: 
                out = model(pixel_values=x.permute(0,2,1,3,4)).logits
            else: 
                out = model(x)
            
            # Softmax í™•ë¥  ê³„ì‚° (Fakeì¼ í™•ë¥ )
            probs = torch.softmax(out, 1)[:, 1]
            preds.extend(probs.cpu().tolist())
            trues.extend(y.cpu().tolist())
            
    # AUC ê³„ì‚° (ì—ëŸ¬ ë°©ì§€ ì²˜ë¦¬)
    try:
        if len(set(trues)) < 2: return 0.5 # ë¼ë²¨ì´ í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš°
        return roc_auc_score(trues, preds)
    except:
        return 0.5

# =========================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰ ë£¨í”„ (Main Pipeline)
# =========================================================
def run_experiment():
    print(f"\nğŸš€ [System Started] Device: {DEVICE}")
    print(f"ğŸ“¦ Datasets: {DATASETS}")
    print(f"ğŸ¤– Models: {MODELS}")
    print("="*60)

    # ì´ë¯¸ì§€ ë³€í™˜ê¸° (Resize & Tensor)
    tf = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224,224)),
        transforms.ToTensor()
    ])

    for ds_name in DATASETS:
        print(f"\nğŸŒ [[ Processing Dataset: {ds_name} ]]")
        files, labels = get_data(ds_name)
        if not files: continue

        # âš–ï¸ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° (Weighted Loss)
        # Real: 300ê°œ, Fake: 135ê°œ (Testë¡œ 30ê°œ ì´ë™í•¨)
        # Weight = 300 / 135 â‰ˆ 2.22
        class_weights = torch.tensor([1.0, 300.0/135.0]).to(DEVICE)
        criterion = nn.CrossEntropyLoss(weight=class_weights)

        # 5-Fold ì„¸íŒ…
        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        
        for model_name in MODELS:
            print(f"\n  ğŸ”¹ Model: {model_name}")
            save_dir = os.path.join("checkpoints", ds_name, model_name)
            os.makedirs(save_dir, exist_ok=True)
            
            # ëª¨ë¸ íƒ€ì… íŒë³„
            is_mae = 'videomae' in model_name
            model_type = 'temporal' if any(x in model_name for x in ['r3d', 'r2', 'mae']) else 'spatial'
            
            # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì • (VideoMAEëŠ” ë¬´ê±°ì›Œì„œ ì¤„ì„)
            current_batches = [2, 4] if is_mae else BATCH_LIST

            # -----------------------------------------------------
            # [Step 1] Grid Search (ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°) - Fold 0ë§Œ ì‚¬ìš©
            # -----------------------------------------------------
            print(f"    ğŸ” Grid Search (Hyperparameter Tuning)...", flush=True)
            
            best_auc = -1
            best_params = {'lr': 1e-4, 'bs': 4} # ê¸°ë³¸ê°’
            
            # ì²« ë²ˆì§¸ Foldë§Œ ì¶”ì¶œ
            train_idx, val_idx = next(skf.split(files, labels))
            
            ds_train = DeepfakeDataset([files[i] for i in train_idx], [labels[i] for i in train_idx], model_type, tf)
            ds_val = DeepfakeDataset([files[i] for i in val_idx], [labels[i] for i in val_idx], model_type, tf)
            
            for lr in LR_LIST:
                for bs in current_batches:
                    # ì§§ê²Œ 3 Epochë§Œ í•™ìŠµí•´ë´„
                    loader_tr = DataLoader(ds_train, batch_size=bs, shuffle=True)
                    loader_val = DataLoader(ds_val, batch_size=bs)
                    
                    model = get_model(model_name, DEVICE)
                    opt = optim.AdamW(model.parameters(), lr=lr)
                    
                    for ep in range(3):
                        train_epoch(model, loader_tr, criterion, opt, is_mae, desc=f"GS LR={lr} BS={bs}")
                    
                    val_auc = evaluate(model, loader_val, is_mae)
                    print(f"      ğŸ‘‰ LR={lr}, BS={bs} -> Val AUC: {val_auc:.4f}")
                    
                    if val_auc > best_auc:
                        best_auc = val_auc
                        best_params = {'lr': lr, 'bs': bs}
            
            print(f"    âœ… Best Params Selected: {best_params} (AUC: {best_auc:.4f})")
            
            # íŒŒë¼ë¯¸í„° ì €ì¥
            with open(os.path.join(save_dir, "best_params.json"), "w") as f:
                json.dump(best_params, f)

            # -----------------------------------------------------
            # [Step 2] Main 5-Fold Training (ë³¸ í•™ìŠµ)
            # -----------------------------------------------------
            print(f"    ğŸš€ Starting 5-Fold Cross Validation...", flush=True)
            final_lr, final_bs = best_params['lr'], best_params['bs']
            
            for fold, (train_idx, val_idx) in enumerate(skf.split(files, labels)):
                ds_train = DeepfakeDataset([files[i] for i in train_idx], [labels[i] for i in train_idx], model_type, tf)
                ds_val = DeepfakeDataset([files[i] for i in val_idx], [labels[i] for i in val_idx], model_type, tf)
                
                loader_tr = DataLoader(ds_train, batch_size=final_bs, shuffle=True)
                loader_val = DataLoader(ds_val, batch_size=final_bs)
                
                model = get_model(model_name, DEVICE)
                opt = optim.AdamW(model.parameters(), lr=final_lr)
                
                best_fold_auc = 0.0
                
                # 10 Epochs ë³¸ í•™ìŠµ
                for ep in range(10):
                    desc_text = f"Fold {fold+1}/5 | Ep {ep+1}/10"
                    train_loss = train_epoch(model, loader_tr, criterion, opt, is_mae, desc=desc_text)
                    val_auc = evaluate(model, loader_val, is_mae)
                    
                    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
                    if val_auc > best_fold_auc:
                        best_fold_auc = val_auc
                        save_path = os.path.join(save_dir, f"fold{fold}_best.pth")
                        torch.save(model.state_dict(), save_path)
                
                print(f"      ğŸ† Fold {fold} Done. Best AUC: {best_fold_auc:.4f}")
            
            print(f"    âœ¨ {model_name} í•™ìŠµ ì™„ë£Œ.")

if __name__ == "__main__":
    run_experiment()