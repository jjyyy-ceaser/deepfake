import os
import subprocess
import pandas as pd
import itertools
import time
from datetime import datetime

# ==========================================
# âš™ï¸ 1. íƒìƒ‰ ê³µê°„ (Grid Search Space)
# ==========================================
# RTX 4070 SUPER (12GB) ë§ì¶¤í˜• ì„¤ì •
PARAM_GRID = {
    "learning_rate": [1e-4, 5e-5, 1e-5],    # í•™ìŠµë¥  3ì¢…
    "batch_size": [4, 8],                   # ë°°ì¹˜ ì‚¬ì´ì¦ˆ 2ì¢… (16ì€ OOM ìœ„í—˜)
    "optimizer": ["adamw", "adam"],         # ì˜µí‹°ë§ˆì´ì € 2ì¢…
}

# íŠœë‹í•  ëª¨ë¸ ëª©ë¡
TARGET_MODELS = [
    "videomae_v2", 
    "r3d_18", 
    "swinv2_tiny", 
    "convnextv2_tiny"
]

# ì‚¬ìš©í•  ë°ì´í„°ì…‹ (ê°•ê±´ì„± í™•ë³´ë¥¼ ìœ„í•´ Mixed ì¶”ì²œ)
DATASET_TYPE = "mixed"  # pure / mixed / worst

# êµì°¨ ê²€ì¦ ì„¤ì •
K_FOLDS = 5
EPOCHS_PER_RUN = 5  # íƒìƒ‰ìš©ì´ë¯€ë¡œ ì§§ê²Œ ì„¤ì •

def run_grid_search():
    results = []
    total_start_time = time.time()
    
    # ê²°ê³¼ ì €ì¥ í´ë”
    os.makedirs("grid_results", exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"grid_results/grid_search_{DATASET_TYPE}_{timestamp}.csv"

    print(f"ğŸš€ Grid Search ì‹œì‘! (Target: {DATASET_TYPE})")
    print(f"   - Models: {TARGET_MODELS}")
    print(f"   - Grid: {PARAM_GRID}")
    
    # 1. ëª¨ë¸ë³„ ë£¨í”„
    for model_name in TARGET_MODELS:
        # VideoMAEëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ë¨¹ìœ¼ë¯€ë¡œ ë°°ì¹˜ ì‚¬ì´ì¦ˆ 8 ì œì™¸ (Safety Lock)
        current_grid = PARAM_GRID.copy()
        if "videomae" in model_name:
            current_grid["batch_size"] = [2, 4]
        
        keys, values = zip(*current_grid.items())
        combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]
        
        print(f"\nğŸ‘‰ [{model_name}] ì´ {len(combinations)}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸ ì˜ˆì •")

        # 2. íŒŒë¼ë¯¸í„° ì¡°í•©ë³„ ë£¨í”„
        for i, params in enumerate(combinations):
            lr = params['learning_rate']
            bs = params['batch_size']
            opt = params['optimizer']
            
            print(f"\n   Testing Combo {i+1}/{len(combinations)}: LR={lr}, BS={bs}, OPT={opt}")
            
            fold_scores = []
            
            # 3. 5-Fold Cross Validation ë£¨í”„
            for fold_idx in range(K_FOLDS):
                print(f"      Running Fold {fold_idx+1}/{K_FOLDS}...", end=" ", flush=True)
                
                # subprocessë¡œ train_universal.py ì‹¤í–‰ (ë©”ëª¨ë¦¬ ì™„ì „ ì´ˆê¸°í™” íš¨ê³¼)
                cmd = [
                    "python", "train_universal.py",
                    "--model", model_name,
                    "--dataset", DATASET_TYPE,
                    "--lr", str(lr),
                    "--batch_size", str(bs),
                    "--optimizer", opt,
                    "--epochs", str(EPOCHS_PER_RUN),
                    "--fold", str(fold_idx),
                    "--k_folds", str(K_FOLDS),
                    "--save_model", "False"  # íƒìƒ‰ ì¤‘ì—” ëª¨ë¸ ì €ì¥ ì•ˆ í•¨ (ìš©ëŸ‰ ì ˆì•½)
                ]
                
                try:
                    # ì‹¤í–‰ ë° ì¶œë ¥ ìº¡ì²˜
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    
                    # ì¶œë ¥ì—ì„œ Validation AUC íŒŒì‹± (train_universal.pyê°€ ì¶œë ¥í•´ì•¼ í•¨)
                    output_lines = result.stdout.split('\n')
                    val_auc = 0.5
                    val_acc = 0.0
                    
                    for line in output_lines:
                        if "FINAL_VAL_AUC:" in line:
                            val_auc = float(line.split(":")[1].strip())
                        if "FINAL_VAL_ACC:" in line:
                            val_acc = float(line.split(":")[1].strip())
                            
                    if result.returncode != 0:
                        print(f"âŒ Error in Fold {fold_idx}: {result.stderr}")
                        val_auc = 0.0 # ì‹¤íŒ¨ ì²˜ë¦¬
                    else:
                        print(f"âœ… Done (AUC: {val_auc:.4f})")
                        
                    fold_scores.append(val_auc)
                    
                except Exception as e:
                    print(f"âŒ Exception: {e}")
                    fold_scores.append(0.0)

            # 5-Fold í‰ê·  ê³„ì‚°
            avg_auc = sum(fold_scores) / K_FOLDS
            print(f"   ğŸ‘‰ Average AUC: {avg_auc:.4f}")
            
            # ê²°ê³¼ ê¸°ë¡
            record = {
                "Model": model_name,
                "Dataset": DATASET_TYPE,
                "LR": lr,
                "BatchSize": bs,
                "Optimizer": opt,
                "Avg_AUC": avg_auc,
                "Fold_Scores": str(fold_scores)
            }
            results.append(record)
            
            # ì¤‘ê°„ ì €ì¥
            pd.DataFrame(results).to_csv(csv_filename, index=False)

    total_time = (time.time() - total_start_time) / 60
    print(f"\nâœ¨ ëª¨ë“  íƒìƒ‰ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {total_time:.1f}ë¶„)")
    print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {csv_filename}")
    
    # ìµœì  ê²°ê³¼ ì¶œë ¥
    df = pd.DataFrame(results)
    best_row = df.loc[df.groupby("Model")["Avg_AUC"].idxmax()]
    print("\nğŸ† ëª¨ë¸ë³„ ìµœì  ì„¤ì • (Best Hyperparameters):")
    print(best_row[["Model", "LR", "BatchSize", "Optimizer", "Avg_AUC"]])

if __name__ == "__main__":
    run_grid_search()