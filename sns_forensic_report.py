import os
import glob
import gc
import torch
import cv2
import numpy as np
import pandas as pd
import timm
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from transformers import VideoMAEForVideoClassification
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score
from tqdm import tqdm

# =====================================================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
# =====================================================================
BASE_DIR = r"C:\Users\leejy\Desktop\test_experiment\dataset\test"
TRAIN_LIST_PATH = r"C:\Users\leejy\Desktop\test_experiment\dataset\train_list.txt"
MODEL_DIR = r"C:\Users\leejy\Desktop\test_experiment"

# ë‹¨ì¼ ê°€ì¤‘ì¹˜ ëª¨ë“œì´ë¯€ë¡œ LRì€ ë°°ì œí•˜ê³ , ëª¨ë¸ íƒ€ì…ê³¼ ì •ê·œí™” ìˆ˜ì¹˜ë§Œ ìœ ì§€í•©ë‹ˆë‹¤.
MODEL_CONFIGS = {
    "xception": {"type": "spatial", "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]},
    "convnext": {"type": "spatial", "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]},
    "swin":     {"type": "spatial", "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]},
    "r3d":      {"type": "temporal", "mean": [0.43216, 0.394666, 0.37645], "std": [0.22803, 0.22145, 0.216989]},
    "r2plus1d": {"type": "temporal", "mean": [0.43216, 0.394666, 0.37645], "std": [0.22803, 0.22145, 0.216989]},
    "videomae": {"type": "videomae", "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]}
}

IMG_SIZE = 224
SEQ_LEN = 16 

# =====================================================================
# 2. ì‹œìŠ¤í…œ ìì› ê´€ë¦¬ ë° ì˜¤ì—¼ ë°©ì§€
# =====================================================================
def clean_memory():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def validate_leakage(test_files, train_list_path):
    if not os.path.exists(train_list_path): return
    with open(train_list_path, 'r', encoding='utf-8') as f:
        train_set = set(os.path.splitext(line.strip())[0] for line in f if line.strip())
    
    if not train_set: return

    for p in test_files:
        fname = os.path.splitext(os.path.basename(p))[0]
        if fname in train_set:
            raise ValueError(f"ğŸš¨ [ì§ì ‘ ì˜¤ì—¼] '{fname}' íŒŒì¼ì€ í•™ìŠµì— ì‚¬ìš©ëœ ë°ì´í„°ì…ë‹ˆë‹¤.")
        try:
            if fname.isdigit(): 
                p_fake = f"fake_svd_{int(fname)+1:03d}"
                if p_fake in train_set: raise ValueError(f"ğŸš¨ [ìŒë°©í–¥ ì˜¤ì—¼] '{fname}'ì˜ ì§ê¿ '{p_fake}'ê°€ í•™ìŠµë¨!")
            elif "fake_svd_" in fname:
                p_real = f"{int(fname.split('_')[-1])-1:05d}"
                if p_real in train_set: raise ValueError(f"ğŸš¨ [ìŒë°©í–¥ ì˜¤ì—¼] '{fname}'ì˜ ì§ê¿ '{p_real}'ì´ í•™ìŠµë¨!")
        except: continue
    print("âœ… ë¬´ê²°ì„± í™•ì¸: ì˜¤ì—¼ë˜ì§€ ì•Šì€ ìˆœìˆ˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…ë‹ˆë‹¤.")

# =====================================================================
# 3. ë°ì´í„° ë¡œë”
# =====================================================================
class FinalTestDataset(Dataset):
    def __init__(self, file_paths, config):
        self.file_paths = file_paths
        self.config = config
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=config['mean'], std=config['std'])
        ])

    def __len__(self): return len(self.file_paths)

    def __getitem__(self, idx):
        path = self.file_paths[idx]
        cap = cv2.VideoCapture(path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if self.config['type'] == "spatial":
            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames // 2)
            ret, frame = cap.read()
            cap.release()
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if ret else np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
            return self.transform(frame), path
        else:
            indices = np.linspace(0, total_frames - 1, SEQ_LEN, dtype=int)
            frames = []
            for i in indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if ret else np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                frames.append(self.transform(frame))
            cap.release()
            return torch.stack(frames).permute(1, 0, 2, 3), path 

# =====================================================================
# 4. ë‹¨ì¼ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì „ìˆ˜ í‰ê°€ ë£¨í”„
# =====================================================================
def start_evaluation():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    final_report = []

    for m_name, config in MODEL_CONFIGS.items():
        # âœ… ì§ê´€ì ì¸ ë‹¨ì¼ ê°€ì¤‘ì¹˜ íŒŒì¼ëª… ë§¤í•‘
        w_file = f"{m_name}_pretrained.pth"
        w_path = os.path.join(MODEL_DIR, w_file)
        
        print(f"\nğŸ”¥ [íƒ€ê²Ÿ ëª¨ë¸] {m_name.upper()}")
        
        if not os.path.exists(w_path):
            print(f"  âš ï¸ ê°€ì¤‘ì¹˜ ì—†ìŒ ê±´ë„ˆëœ€: '{w_file}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        # ê°€ì¤‘ì¹˜ê°€ ì¡´ì¬í•˜ë©´ 1íšŒë§Œ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ
        print(f"  âœ… '{w_file}' ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ. í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        if config['type'] == "spatial":
            model = timm.create_model(m_name if 'swin' not in m_name else 'swin_tiny_patch4_window7_224', pretrained=False, num_classes=2)
            if m_name == "convnext": model = timm.create_model('convnext_tiny', pretrained=False, num_classes=2)
        elif config['type'] == "temporal":
            model = models.video.r3d_18() if m_name == "r3d" else models.video.r2plus1d_18()
            model.fc = torch.nn.Linear(model.fc.in_features, 2)
        else:
            model = VideoMAEForVideoClassification.from_pretrained("MCG-NJU/videomae-base", num_labels=2, ignore_mismatched_sizes=True)
        
        # ì™¸ë¶€ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œ í…ì„œ ì‚¬ì´ì¦ˆ ë¶ˆì¼ì¹˜ë¥¼ ëŒ€ë¹„í•œ strict=False ì²˜ë¦¬
        model.load_state_dict(torch.load(w_path, map_location=device), strict=False)
        model.to(device).eval()

        for mc in ["case1", "case4"]:
            for pf_label, pf_folder in {"Raw": "raw", "YouTube": "youtube", "Instagram": "instagram", "Kakao_Normal": "kakao_normal", "Kakao_High": "kakao_high"}.items():
                t_path = os.path.join(BASE_DIR, mc, pf_folder)
                r_files = sorted(glob.glob(os.path.join(t_path, "real", "*.mp4")))
                f_files = sorted(glob.glob(os.path.join(t_path, "fake", "*.mp4")))
                
                if not r_files or not f_files: continue
                test_files = r_files + f_files
                labels = [0] * len(r_files) + [1] * len(f_files)

                if pf_label == "Raw" and mc == "case1": validate_leakage(test_files, TRAIN_LIST_PATH)

                loader = DataLoader(FinalTestDataset(test_files, config), batch_size=4, num_workers=4, pin_memory=True)
                
                probs = []
                with torch.no_grad():
                    for inputs, _ in tqdm(loader, desc=f"[{mc.upper()}] {pf_label}", leave=False):
                        inputs = inputs.to(device)
                        if config['type'] == "videomae":
                            outputs = model(pixel_values=inputs.permute(0, 2, 1, 3, 4)).logits
                        else: 
                            outputs = model(inputs)
                        probs.extend(torch.softmax(outputs, dim=1)[:, 1].cpu().numpy())
                
                preds = [1 if p > 0.5 else 0 for p in probs]
                
                # ë‹¨ì¼ í‰ê°€ ê²°ê³¼ ì ì¬
                final_report.append({
                    "Model": m_name, "Case": mc, "Platform": pf_label,
                    "Acc": accuracy_score(labels, preds),
                    "AUC": roc_auc_score(labels, probs),
                    "F1": f1_score(labels, preds, zero_division=0),
                    "Precision": precision_score(labels, preds, zero_division=0),
                    "Recall": recall_score(labels, preds, zero_division=0)
                })
        
        # ëª¨ë¸ í‰ê°€ê°€ ì™„ì „íˆ ëë‚˜ë©´ ë©”ëª¨ë¦¬ì—ì„œ íŒŒê¸°
        del model
        clean_memory()

    if final_report:
        df_report = pd.DataFrame(final_report)
        output_excel_path = "Final_Robustness_Analysis.xlsx"
        df_report.to_excel(output_excel_path, index=False)
        print(f"\nâœ… ëª¨ë“  í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. '{output_excel_path}' íŒŒì¼ì—ì„œ 5ëŒ€ ì§€í‘œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.")
    else:
        print("\nğŸš¨ í‰ê°€ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê°€ì¤‘ì¹˜ íŒŒì¼ëª…ì´ë‚˜ í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ ê²½ë¡œë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    start_evaluation()