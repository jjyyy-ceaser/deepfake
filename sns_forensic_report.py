import os
import glob
import gc
import torch
import cv2
import numpy as np
import pandas as pd
import timm
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from transformers import VideoMAEForVideoClassification
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score
from tqdm import tqdm

# =====================================================================
# 1. [ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ ë° ëª¨ë¸ë³„ ìµœì  ì„¸íŒ…]
# =====================================================================
BASE_DIR = r"C:\Users\leejy\Desktop\test_experiment\dataset\test"
TRAIN_LIST_PATH = r"C:\Users\leejy\Desktop\test_experiment\dataset\train_list.txt"
MODEL_DIR = r"C:\Users\leejy\Desktop\test_experiment"

# [ê·¸ë¦¬ë“œ ì„œì¹˜(grid_search_master_results.csv) ê¸°ë°˜ ìµœì  LR ë° ëª¨ë¸ë³„ ì„¤ì •]
# í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ìµœì ì˜ ì •ê·œí™”(Mean/Std) ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì´ì‹
MODEL_CONFIGS = {
    "xception": {
        "type": "spatial", "best_lr": 5e-05, 
        "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]
    },
    "convnext": {
        "type": "spatial", "best_lr": 1e-04, 
        "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]
    },
    "swin": {
        "type": "spatial", "best_lr": 5e-05, 
        "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]
    },
    "r3d": {
        "type": "temporal", "best_lr": 1e-04, 
        "mean": [0.43216, 0.394666, 0.37645], "std": [0.22803, 0.22145, 0.216989]
    },
    "r2plus1d": {
        "type": "temporal", "best_lr": 1e-04, 
        "mean": [0.43216, 0.394666, 0.37645], "std": [0.22803, 0.22145, 0.216989]
    },
    "videomae": {
        "type": "videomae", "best_lr": 5e-05, 
        "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]
    }
}

IMG_SIZE = 224
SEQ_LEN = 16 
NUM_FOLDS = 5

# =====================================================================
# 2. [ìì› ìµœì í™” ë° ë¬´ê²°ì„± ê²€ì¦ ì‹œìŠ¤í…œ]
# =====================================================================
def clean_memory():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def validate_leakage(test_files, train_list_path):
    """
    [ë°ì´í„° ì˜¤ì—¼ ë°©ì§€ ë¡œì§]
    ì‚¬ìš©ì ì •ì˜ ì˜¤í”„ì…‹ ë°˜ì˜: Real(N) <-> Fake(N+1)
    """
    if not os.path.exists(train_list_path): return
    with open(train_list_path, 'r', encoding='utf-8') as f:
        train_set = set(os.path.splitext(line.strip())[0] for line in f if line.strip())
    
    if not train_set: return

    for p in test_files:
        fname = os.path.splitext(os.path.basename(p))[0]
        if fname in train_set:
            raise ValueError(f"ğŸš¨ [ì˜¤ì—¼] '{fname}'ì€(ëŠ”) ì´ë¯¸ í•™ìŠµëœ ë°ì´í„°ì…ë‹ˆë‹¤.")
        
        # ì˜¤í”„ì…‹ ê·œì¹™ ì²´í¬
        try:
            if fname.isdigit():
                p_fake = f"fake_svd_{int(fname)+1:03d}"
                if p_fake in train_set: raise ValueError(f"ğŸš¨ [ì˜¤ì—¼] '{fname}'ì˜ ì§ê¿ '{p_fake}'ê°€ í•™ìŠµë¨!")
            elif "fake_svd_" in fname:
                p_real = f"{int(fname.split('_')[-1])-1:05d}"
                if p_real in train_set: raise ValueError(f"ğŸš¨ [ì˜¤ì—¼] '{fname}'ì˜ ì§ê¿ '{p_real}'ì´(ê°€) í•™ìŠµë¨!")
        except: continue
    print("âœ… ë¬´ê²°ì„± í™•ì¸: í•™ìŠµ ë¦¬ìŠ¤íŠ¸ì™€ ê²¹ì¹˜ì§€ ì•ŠëŠ” ìˆœìˆ˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.")

# =====================================================================
# 3. [ë°ì´í„° ë¡œë”] ìµœì  ë¡œë”© ì†ë„ ì ìš©
# =====================================================================
class FinalTestDataset(Dataset):
    def __init__(self, file_paths, config):
        self.file_paths = file_paths
        self.config = config
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=config['mean'], std=config['std'])
        ])

    def __len__(self): return len(self.file_paths)

    def __getitem__(self, idx):
        path = self.file_paths[idx]
        cap = cv2.VideoCapture(path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if self.config['type'] == "spatial":
            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames // 2)
            ret, frame = cap.read()
            cap.release()
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if ret else np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
            return self.transform(frame), path
        else:
            indices = np.linspace(0, total_frames - 1, SEQ_LEN, dtype=int)
            frames = []
            for i in indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if ret else np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                frames.append(self.transform(frame))
            cap.release()
            return torch.stack(frames).permute(1, 0, 2, 3), path 

# =====================================================================
# 4. [ë©”ì¸ í‰ê°€ ì—”ì§„] ìµœì  LR ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¶”ë¡ 
# =====================================================================
def start_evaluation():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    final_report = []

    for m_name, config in MODEL_CONFIGS.items():
        print(f"\nğŸ”¥ [íƒ€ê²Ÿ ëª¨ë¸] {m_name.upper()} (Best LR: {config['best_lr']})")
        
        for mc in ["case1", "case4"]:
            for pf_label, pf_folder in {"Raw": "raw", "YouTube": "youtube", "Instagram": "instagram", "Kakao_Normal": "kakao_normal", "Kakao_High": "kakao_high"}.items():
                t_path = os.path.join(BASE_DIR, mc, pf_folder)
                r_files = sorted(glob.glob(os.path.join(t_path, "real", "*.mp4")))
                f_files = sorted(glob.glob(os.path.join(t_path, "fake", "*.mp4")))
                
                if not r_files or not f_files: continue
                test_files = r_files + f_files
                labels = [0]*len(r_files) + [1]*len(f_files)

                if pf_label == "Raw" and mc == "case1": validate_leakage(test_files, TRAIN_LIST_PATH)

                fold_res = []
                for f in range(1, NUM_FOLDS + 1):
                    # ê°€ì¤‘ì¹˜ íŒŒì¼ íƒìƒ‰ (Best LR ë²„ì „ ë¡œë“œ)
                    w_file = f"model_{config['type']}_{m_name}_pure_fold{f}.pth"
                    if m_name == "videomae": w_file = f"model_temporal_videomae_pure_fold{f}.pth"
                    
                    w_path = os.path.join(MODEL_DIR, w_file)
                    if not os.path.exists(w_path): continue
                    
                    # ëª¨ë¸ ë¡œë“œ
                    if config['type'] == "spatial":
                        model = timm.create_model(m_name if 'swin' not in m_name else 'swin_tiny_patch4_window7_224', pretrained=False, num_classes=2)
                        if m_name == "convnext": model = timm.create_model('convnext_tiny', pretrained=False, num_classes=2)
                    elif config['type'] == "temporal":
                        model = models.video.r3d_18() if m_name == "r3d" else models.video.r2plus1d_18()
                        model.fc = torch.nn.Linear(model.fc.in_features, 2)
                    else: # videomae
                        model = VideoMAEForVideoClassification.from_pretrained("MCG-NJU/videomae-base", num_labels=2, ignore_mismatched_sizes=True)
                    
                    model.load_state_dict(torch.load(w_path, map_location=device))
                    model.to(device).eval()
                    
                    # DataLoader ì„¤ì • (num_workers=4, pin_memory=True ë°˜ì˜)
                    loader = DataLoader(FinalTestDataset(test_files, config), batch_size=4, num_workers=4, pin_memory=True)
                    
                    probs = []
                    with torch.no_grad():
                        for inputs, _ in tqdm(loader, desc=f"Fold {f}", leave=False):
                            inputs = inputs.to(device)
                            if config['type'] == "videomae":
                                outputs = model(pixel_values=inputs.permute(0, 2, 1, 3, 4)).logits
                            else: outputs = model(inputs)
                            probs.extend(torch.softmax(outputs, dim=1)[:, 1].cpu().numpy())
                    
                    preds = [1 if p > 0.5 else 0 for p in probs]
                    fold_res.append({"acc": accuracy_score(labels, preds), "auc": roc_auc_score(labels, probs)})
                    del model; clean_memory() # ğŸ§¼ ë©”ëª¨ë¦¬ ì¦‰ì‹œ ì •ë¦¬

                if fold_res:
                    final_report.append({
                        "Model": m_name, "Case": mc, "Platform": pf_label,
                        "Acc": np.mean([x['acc'] for x in fold_res]),
                        "AUC": np.mean([x['auc'] for x in fold_res])
                    })

    pd.DataFrame(final_report).to_csv("Final_Robustness_Analysis.csv", index=False)
    print("\nâœ… í‰ê°€ ì™„ë£Œ. 'Final_Robustness_Analysis.csv'ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.")

if __name__ == "__main__":
    start_evaluation()