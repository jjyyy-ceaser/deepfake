import os
import glob
import gc
import torch
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score
from sklearn.model_selection import KFold
from tqdm import tqdm


# =====================================================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
# =====================================================================
BASE_DIR = r"C:\Users\leejy\Desktop\test_experiment\dataset\test"
TRAIN_LIST_PATH = r"C:\Users\leejy\Desktop\test_experiment\dataset\train_list.txt"

MAIN_CASES = ["case1", "case4"]
PLATFORMS = {
    "Raw": "raw", 
    "YouTube": "youtube",
    "Instagram": "instagram",
    "Kakao_Normal": "kakao_normal",
    "Kakao_High": "kakao_high"
}
NUM_FOLDS = 5

# ëŒ€ìƒ ëª¨ë¸ íƒ€ì… ì„¤ì • ("spatial", "temporal", "videomae" ì¤‘ íƒ 1)
MODEL_TYPE = "temporal"
BATCH_SIZE = 32 if MODEL_TYPE == "spatial" else 4

# =====================================================================
# 2. ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ë¬´ê²°ì„± ê²€ì¦ ë¡œì§
# =====================================================================
def clean_memory():
    """âœ¨ GPU VRAM ë° ì‹œìŠ¤í…œ RAM ìºì‹œ ê°•ì œ ë°˜í™˜ âœ¨"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    print("    ğŸ§¹ [ë©”ëª¨ë¦¬ í™˜ìˆ˜ ì™„ë£Œ] VRAM/RAM ëˆ„ìˆ˜ ë°©ì§€ ì¡°ì¹˜ ì ìš©ë¨.")

def validate_no_data_leakage(test_files, train_list_path):
    print("\n" + "="*70)
    print("ğŸ›¡ï¸ [ë‹¨ê³„ 1] ë°ì´í„° ì˜¤ì—¼(Data Leakage) ì‚¬ì „ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ê²€ì¦")
    print("="*70)
    
    if not os.path.exists(train_list_path):
        print("âš ï¸ í•™ìŠµ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ë¬´ê²°ì„± ê²€ì¦ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
        
    with open(train_list_path, 'r', encoding='utf-8') as f:
        train_set = set(os.path.splitext(line.strip())[0] for line in f if line.strip())
        
    test_set = set(os.path.splitext(os.path.basename(p))[0] for p in test_files)
    leakage = train_set.intersection(test_set)
    
    if leakage:
        raise ValueError(f"ğŸš¨ [ì¹˜ëª…ì  ì˜¤ë¥˜] ë°ì´í„° ì˜¤ì—¼ ê°ì§€! ì¤‘ë³µ: {list(leakage)[:5]} ... ì‹¤í—˜ ê°•ì œ ì¤‘ë‹¨.")
    print("âœ… ë¬´ê²°ì„± í™•ì¸: í•™ìŠµ ë°ì´í„°ì™€ í‰ê°€ ë°ì´í„°ê°€ 100% ë…ë¦½ì ì…ë‹ˆë‹¤.")

# =====================================================================
# 3. ê³ ì† ë°°ì¹˜ ê¸°ë°˜ DataLoader ë° ì¶”ë¡  ì—”ì§„
# =====================================================================
class VideoInferenceDataset(Dataset):
    def __init__(self, file_paths, model_type="spatial"):
        self.file_paths = file_paths
        self.model_type = model_type
        # TODO: ì‚¬ìš©ìì˜ train_*.py íŒŒì¼ ë‚´ transform ë¡œì§ ì´ì‹ í•„ìš”
        
    def __len__(self):
        return len(self.file_paths)
        
    def __getitem__(self, idx):
        path = self.file_paths[idx]
        # ë”ë¯¸ í…ì„œ (ì‹¤ì œ CV2/Torchvision ë³€í™˜ ë¡œì§ìœ¼ë¡œ êµì²´)
        dummy_tensor = torch.zeros((3, 224, 224)) if self.model_type == "spatial" else torch.zeros((3, 16, 224, 224))
        return dummy_tensor, path

def run_batch_inference(file_paths, model, device="cuda"):
    dataset = VideoInferenceDataset(file_paths, model_type=MODEL_TYPE)
    loader = DataLoader(
        dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False,
        num_workers=8,        # ë³‘ëª© í•´ì†Œ í•µì‹¬ 1
        pin_memory=True,      # ë³‘ëª© í•´ì†Œ í•µì‹¬ 2
        prefetch_factor=2,    # ë³‘ëª© í•´ì†Œ í•µì‹¬ 3
        persistent_workers=True
    )
    
    predictions, confidences = [], []
    model.eval()
    
    with torch.no_grad():
        for inputs, paths in tqdm(loader, desc="ì¶”ë¡  ì§„í–‰ ì¤‘", leave=False):
            inputs = inputs.to(device)
            # TODO: ì‹¤ì œ ì¶”ë¡  ë¡œì§ (ì˜ˆ: outputs = model(inputs); probs = torch.sigmoid(outputs))
            
            # ì•„ë˜ëŠ” ë¡œì§ ì¤‘ë‹¨ ë°©ì§€ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±ê¸°
            batch_preds = [1 if "fake" in p.lower() else 0 for p in paths]
            batch_confs = [0.85 if "fake" in p.lower() else 0.15 for p in paths]
            
            predictions.extend(batch_preds)
            confidences.extend(batch_confs)
            
    del loader, dataset  # ì¦‰ê°ì ì¸ ì°¸ì¡° í•´ì œ
    return predictions, confidences

# =====================================================================
# 4. ë‹¨ì¼ ì¼€ì´ìŠ¤-í”Œë«í¼ í‰ê°€ ë° DataFrame ì ì¬
# =====================================================================
def evaluate_condition(main_case, platform_key, platform_folder, model, device="cuda"):
    target_path = os.path.join(BASE_DIR, main_case, platform_folder)
    real_files = sorted(glob.glob(os.path.join(target_path, "real", "*.*")))
    fake_files = sorted(glob.glob(os.path.join(target_path, "fake", "*.*")))
    
    if len(real_files) != len(fake_files) or len(real_files) == 0:
        raise ValueError(f"[{main_case} - {platform_key}] ë°ì´í„° 1:1 ìŒ ë¶ˆì¼ì¹˜ í˜¹ì€ í´ë” ë¹„ì–´ìˆìŒ.")
        
    print(f"\nâ–¶ [{main_case} - {platform_key}] ë°ì´í„° ì ì¬ ë° ì¶”ë¡  ì‹œì‘...")
    
    r_preds, r_confs = run_batch_inference(real_files, model, device)
    f_preds, f_confs = run_batch_inference(fake_files, model, device)
    
    results = []
    for i in range(len(real_files)):
        results.append({"pair_id": i, "filename": os.path.basename(real_files[i]), "true_label": 0, "pred_label": r_preds[i], "confidence": r_confs[i]})
        results.append({"pair_id": i, "filename": os.path.basename(fake_files[i]), "true_label": 1, "pred_label": f_preds[i], "confidence": f_confs[i]})
        
    return pd.DataFrame(results)

def calculate_metrics(df):
    y_true, y_pred, y_prob = df["true_label"], df["pred_label"], df["confidence"]
    return {
        "Acc": accuracy_score(y_true, y_pred),
        "Pre": precision_score(y_true, y_pred, zero_division=0),
        "Rec": recall_score(y_true, y_pred, zero_division=0),
        "F1":  f1_score(y_true, y_pred, zero_division=0),
        "AUC": roc_auc_score(y_true, y_prob)
    }

# =====================================================================
# 5. ì—„ê²©í•œ ë³€ì¸ í†µì œ ê¸°ë°˜ 2D ë‹¤ì¤‘ K-Fold êµì°¨ ë¶„ì„
# =====================================================================
def run_matrix_kfold_analysis(case_data_dict):
    print("\n" + "="*80)
    print("ğŸ“Š [ë‹¨ê³„ 2] K-Fold (5-Fold) ë³€ì¸ í†µì œ ë§¤íŠ¸ë¦­ìŠ¤ ë¶„ì„ ì‹œì‘")
    print("="*80)
    
    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)
    pair_ids = case_data_dict["case1"]["Raw"]['pair_id'].unique()
    
    fold_results = {mc: {pf: {m: [] for m in ["Acc", "Pre", "Rec", "F1", "AUC"]} for pf in PLATFORMS.keys()} for mc in MAIN_CASES}
    
    for fold, (_, test_idx) in enumerate(kf.split(pair_ids), 1):
        test_pairs = pair_ids[test_idx]
        
        for mc in MAIN_CASES:
            for pf in PLATFORMS.keys():
                df_target = case_data_dict[mc][pf]
                fold_data = df_target[df_target['pair_id'].isin(test_pairs)]
                
                # [ë³€ì¸ í†µì œ í•„ìˆ˜ ì²´í¬] ìŒ(Pair) ë°ì´í„° ëˆ„ë½ ë° ì„ì„ ë°©ì§€
                assert len(fold_data) == len(test_pairs) * 2, f"Fold {fold}: {mc}-{pf} 1:1 ë§¤ì¹­ ì˜¤ë¥˜ ë°œìƒ!"
                
                res = calculate_metrics(fold_data)
                for m in res.keys():
                    fold_results[mc][pf][m].append(res[m])

    metrics_list = ["Acc", "AUC", "F1", "Pre", "Rec"]
    for m in metrics_list:
        print(f"\n[{m} ì§€í‘œ (Mean Â± Std)]")
        print(f"{'Platform':<15} | {'Case 1 (Baseline)':<20} | {'Case 4 (Extreme)':<20}")
        print("-" * 65)
        for pf in PLATFORMS.keys():
            c1_mean, c1_std = np.mean(fold_results["case1"][pf][m]), np.std(fold_results["case1"][pf][m])
            c4_mean, c4_std = np.mean(fold_results["case4"][pf][m]), np.std(fold_results["case4"][pf][m])
            print(f"{pf:<15} | {c1_mean:.4f} (Â±{c1_std:.4f}) | {c4_mean:.4f} (Â±{c4_std:.4f})")

# =====================================================================
# 6. ë©”ì¸ ì‹¤í–‰ íŠ¸ë¦¬ê±°
# =====================================================================
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    target_models = ["r3d_temporal_model", "swin_spatial_model"] # ì˜ˆì‹œ
    
    # 1. í‰ê°€ ì‹œì‘ ì „ ìµœì´ˆ 1íšŒ ì „ì²´ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ (Raw ê¸°ì¤€)
    test_target_files = glob.glob(os.path.join(BASE_DIR, "case1", "raw", "real", "*.*")) + \
                        glob.glob(os.path.join(BASE_DIR, "case1", "raw", "fake", "*.*"))
    validate_no_data_leakage(test_target_files, TRAIN_LIST_PATH)
    
    for model_name in target_models:
        print(f"\n\n{'#'*80}")
        print(f"ğŸš€ [íƒ€ê²Ÿ ëª¨ë¸ ì¶”ë¡  ì‹œì‘] {model_name}")
        print(f"{'#'*80}")
        
        # TODO: ì‹¤ì œ ê°€ì¤‘ì¹˜ ë¡œë“œ ì½”ë“œ ì‚½ì… ìœ„ì¹˜
        dummy_model_instance = torch.nn.Linear(10, 2).to(device) 
        all_results = {mc: {} for mc in MAIN_CASES}
        
        for mc in MAIN_CASES:
            for pf_key, pf_folder in PLATFORMS.items():
                # ê°œë³„ ì¡°ê±´ ì¶”ë¡ 
                all_results[mc][pf_key] = evaluate_condition(mc, pf_key, pf_folder, dummy_model_instance, device)
                # í‰ê°€ í›„ ë©”ëª¨ë¦¬ ì¦‰ê° í™˜ìˆ˜
                clean_memory()
                
        # ì¢…í•© ë§¤íŠ¸ë¦­ìŠ¤ ë„ì¶œ
        run_matrix_kfold_analysis(all_results)
        
        # ëª¨ë¸ ì™„ì „ íê¸° ë° VRAM ë°˜í™˜ (ë‹¤ìŒ ëª¨ë¸ í‰ê°€ ì¤€ë¹„)
        del dummy_model_instance
        clean_memory()
        print(f"ğŸ [{model_name}] ëª¨ë¸ í‰ê°€ ì™„ì „ ì¢…ë£Œ.")