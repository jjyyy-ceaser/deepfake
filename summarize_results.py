import os
import glob
import gc
import torch
import cv2
import numpy as np
import pandas as pd
import timm
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from transformers import VideoMAEForVideoClassification
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from tqdm import tqdm

# =====================================================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë° ìµœì í™” ì„¸íŒ… (ê·¸ë¦¬ë“œ ì„œì¹˜ ë° í›ˆë ¨ ì½”ë“œ ê¸°ì¤€)
# =====================================================================
BASE_DIR = r"C:\Users\leejy\Desktop\test_experiment\dataset\test"
TRAIN_LIST_PATH = r"C:\Users\leejy\Desktop\test_experiment\dataset\train_list.txt"
MODEL_DIR = r"C:\Users\leejy\Desktop\test_experiment"

# 6ê°œ ëª¨ë¸: ì•„í‚¤í…ì²˜ íƒ€ì…, ê·¸ë¦¬ë“œ ì„œì¹˜ Best LR, í›ˆë ¨ ì‹œ ì ìš©ëœ ìµœì  Normalize ìˆ˜ì¹˜
MODEL_CONFIGS = {
    "xception": {
        "type": "spatial", "best_lr": 5e-05, 
        "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]
    },
    "convnext": {
        "type": "spatial", "best_lr": 1e-04, 
        "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]
    },
    "swin": {
        "type": "spatial", "best_lr": 5e-05, 
        "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]
    },
    "r3d": {
        "type": "temporal", "best_lr": 1e-04, 
        "mean": [0.43216, 0.394666, 0.37645], "std": [0.22803, 0.22145, 0.216989]
    },
    "r2plus1d": {
        "type": "temporal", "best_lr": 1e-04, 
        "mean": [0.43216, 0.394666, 0.37645], "std": [0.22803, 0.22145, 0.216989]
    },
    "videomae": {
        "type": "videomae", "best_lr": 5e-05, 
        "mean": [0.485, 0.456, 0.406], "std": [0.229, 0.224, 0.225]
    }
}

IMG_SIZE = 224
SEQ_LEN = 16 
NUM_FOLDS = 5

# =====================================================================
# 2. ì‹œìŠ¤í…œ ìì› ê´€ë¦¬ ë° ë°ì´í„° ì˜¤ì—¼(Leakage) ì›ì²œ ì°¨ë‹¨
# =====================================================================
def clean_memory():
    """VRAM ë° RAM ë©”ëª¨ë¦¬ ì°Œêº¼ê¸° ê°•ì œ ë°˜í™˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def validate_leakage(test_files, train_list_path):
    """
    í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ë³µ ê²€ì‚¬
    [í•µì‹¬] ì˜¤í”„ì…‹ ê·œì¹™ ìŒë°©í–¥ ë°©ì–´: Real 00000 <-> Fake fake_svd_001
    """
    if not os.path.exists(train_list_path): return
    with open(train_list_path, 'r', encoding='utf-8') as f:
        train_set = set(os.path.splitext(line.strip())[0] for line in f if line.strip())
    
    if not train_set: return

    for p in test_files:
        fname = os.path.splitext(os.path.basename(p))[0]
        
        # 1. íŒŒì¼ ì´ë¦„ ì§ì ‘ ì¼ì¹˜ ê²€ì‚¬
        if fname in train_set:
            raise ValueError(f"ğŸš¨ [ì§ì ‘ ì˜¤ì—¼] '{fname}' íŒŒì¼ì€ í•™ìŠµì— ì‚¬ìš©ëœ ë°ì´í„°ì…ë‹ˆë‹¤.")
        
        # 2. ì˜¤í”„ì…‹ ìŒë°©í–¥ ì¼ì¹˜ ê²€ì‚¬
        try:
            if fname.isdigit(): # Real íŒŒì¼ (ì˜ˆ: '00000')
                p_fake = f"fake_svd_{int(fname)+1:03d}"
                if p_fake in train_set: 
                    raise ValueError(f"ğŸš¨ [ìŒë°©í–¥ ì˜¤ì—¼] ì§„ì§œ ì˜ìƒ '{fname}'ì˜ ì§ê¿ '{p_fake}'ê°€ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤!")
            elif "fake_svd_" in fname: # Fake íŒŒì¼ (ì˜ˆ: 'fake_svd_001')
                p_real = f"{int(fname.split('_')[-1])-1:05d}"
                if p_real in train_set: 
                    raise ValueError(f"ğŸš¨ [ìŒë°©í–¥ ì˜¤ì—¼] ê°€ì§œ ì˜ìƒ '{fname}'ì˜ ì§ê¿ '{p_real}'ì´ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤!")
        except Exception:
            continue
            
    print("âœ… ë°ì´í„° ë¬´ê²°ì„± í™•ì¸: í•™ìŠµ ë°ì´í„°ì™€ í‰ê°€ ë°ì´í„°ê°€ 100% ë¶„ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

# =====================================================================
# 3. ëª¨ë¸ë³„ í”„ë ˆì„ ì¶”ì¶œì„ ìœ„í•œ ë°ì´í„° ë¡œë”
# =====================================================================
class FinalTestDataset(Dataset):
    def __init__(self, file_paths, config):
        self.file_paths = file_paths
        self.config = config
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=config['mean'], std=config['std'])
        ])

    def __len__(self): return len(self.file_paths)

    def __getitem__(self, idx):
        path = self.file_paths[idx]
        cap = cv2.VideoCapture(path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if self.config['type'] == "spatial":
            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames // 2)
            ret, frame = cap.read()
            cap.release()
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if ret else np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
            return self.transform(frame), path
        else:
            indices = np.linspace(0, total_frames - 1, SEQ_LEN, dtype=int)
            frames = []
            for i in indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if ret else np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                frames.append(self.transform(frame))
            cap.release()
            return torch.stack(frames).permute(1, 0, 2, 3), path 

# =====================================================================
# 4. ì¢…í•© í‰ê°€ ë©”ì¸ ë£¨í”„ (ì—‘ì…€ ì €ì¥ í¬í•¨)
# =====================================================================
def start_evaluation():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    final_report = []

    for m_name, config in MODEL_CONFIGS.items():
        print(f"\nğŸ”¥ [íƒ€ê²Ÿ ëª¨ë¸] {m_name.upper()} (Best LR: {config['best_lr']})")
        
        for mc in ["case1", "case4"]:
            for pf_label, pf_folder in {"Raw": "raw", "YouTube": "youtube", "Instagram": "instagram", "Kakao_Normal": "kakao_normal", "Kakao_High": "kakao_high"}.items():
                t_path = os.path.join(BASE_DIR, mc, pf_folder)
                r_files = sorted(glob.glob(os.path.join(t_path, "real", "*.mp4")))
                f_files = sorted(glob.glob(os.path.join(t_path, "fake", "*.mp4")))
                
                if not r_files or not f_files: continue
                test_files = r_files + f_files
                labels = [0] * len(r_files) + [1] * len(f_files)

                # ìµœì´ˆ 1íšŒ ê¸°ì¤€ ì¼€ì´ìŠ¤ ê²€ì‚¬ (ì˜¤ì—¼ë°©ì§€ ì•Œê³ ë¦¬ì¦˜ ì‘ë™)
                if pf_label == "Raw" and mc == "case1": 
                    validate_leakage(test_files, TRAIN_LIST_PATH)

                fold_res = []
                for f in range(1, NUM_FOLDS + 1):
                    # pth ê°€ì¤‘ì¹˜ íŒŒì¼ëª… ë§¤ì¹­
                    w_file = f"model_{config['type']}_{m_name}_pure_fold{f}.pth"
                    if m_name == "videomae": w_file = f"model_temporal_videomae_pure_fold{f}.pth"
                    
                    w_path = os.path.join(MODEL_DIR, w_file)
                    if not os.path.exists(w_path): continue
                    
                    # ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¡œë“œ
                    if config['type'] == "spatial":
                        model = timm.create_model(m_name if 'swin' not in m_name else 'swin_tiny_patch4_window7_224', pretrained=False, num_classes=2)
                        if m_name == "convnext": model = timm.create_model('convnext_tiny', pretrained=False, num_classes=2)
                    elif config['type'] == "temporal":
                        model = models.video.r3d_18() if m_name == "r3d" else models.video.r2plus1d_18()
                        model.fc = torch.nn.Linear(model.fc.in_features, 2)
                    else:
                        model = VideoMAEForVideoClassification.from_pretrained("MCG-NJU/videomae-base", num_labels=2, ignore_mismatched_sizes=True)
                    
                    model.load_state_dict(torch.load(w_path, map_location=device))
                    model.to(device).eval()
                    
                    # ë°ì´í„° ë¡œë” ìµœì  ì„¸íŒ… (num_workers=4, pin_memory=True)
                    loader = DataLoader(FinalTestDataset(test_files, config), batch_size=4, num_workers=4, pin_memory=True)
                    
                    probs = []
                    with torch.no_grad():
                        for inputs, _ in tqdm(loader, desc=f"Fold {f}", leave=False):
                            inputs = inputs.to(device)
                            if config['type'] == "videomae":
                                outputs = model(pixel_values=inputs.permute(0, 2, 1, 3, 4)).logits
                            else: 
                                outputs = model(inputs)
                            probs.extend(torch.softmax(outputs, dim=1)[:, 1].cpu().numpy())
                    
                    preds = [1 if p > 0.5 else 0 for p in probs]
                    fold_res.append({"acc": accuracy_score(labels, preds), "auc": roc_auc_score(labels, probs), "f1": f1_score(labels, preds, zero_division=0)})
                    del model; clean_memory() # âœ¨ ë©”ëª¨ë¦¬ ì¦‰ê° í•´ì œ

                # 5-Fold í‰ê·  ìš”ì•½
                if fold_res:
                    final_report.append({
                        "Model": m_name, "Case": mc, "Platform": pf_label,
                        "Acc": np.mean([x['acc'] for x in fold_res]),
                        "AUC": np.mean([x['auc'] for x in fold_res]),
                        "F1": np.mean([x['f1'] for x in fold_res])
                    })

    # ğŸ“Š ì—‘ì…€ íŒŒì¼(.xlsx)ë¡œ ì¶œë ¥ (pandasì˜ to_excel ì‚¬ìš©)
    df_report = pd.DataFrame(final_report)
    output_excel_path = "Final_Robustness_Analysis.xlsx"
    df_report.to_excel(output_excel_path, index=False)
    print(f"\nâœ… ëª¨ë“  í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. '{output_excel_path}' íŒŒì¼ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.")

if __name__ == "__main__":
    start_evaluation()