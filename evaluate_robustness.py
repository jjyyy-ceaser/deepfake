import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
import cv2
import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import timm
from transformers import VideoMAEForVideoClassification
from sklearn.metrics import accuracy_score, roc_auc_score

# ==========================================
# âš™ï¸ 1. ì¥ë¹„ ì ê²€ ë° ê²½ë¡œ ì„¤ì • (ë¹¨ê°„ ì¤„ í•´ê²°)
# ==========================================
# ìœˆë„ìš° ê²½ë¡œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ìŠ¬ë˜ì‹œ(/)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
BASE_DIR = "C:/Users/leejy/Desktop/test_experiment/dataset"
MODEL_DIR = "C:/Users/leejy/Desktop/test_experiment"

# GPU ê°•ì œ í• ë‹¹: GPUê°€ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ë°”ë¡œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì—¬ ë©ˆì¶¥ë‹ˆë‹¤.
if not torch.cuda.is_available():
    raise RuntimeError("âŒ GPU(CUDA)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! ê°€ìƒí™˜ê²½ ì„¤ì •ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")

DEVICE = torch.device("cuda")
print(f"âœ… ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜: {torch.cuda.get_device_name(0)}")

DOMAINS = ["3_test_svd", "4_test_runway", "5_test_pika", "6_test_ffpp"]
CASES = ["case1", "case2", "case3", "case4"]
SEQ_LEN = 16

# ==========================================
# ğŸ“‚ 2. í‰ê°€ìš© ë°ì´í„°ì…‹ í´ë˜ìŠ¤
# ==========================================
class RobustnessEvalDataset(Dataset):
    def __init__(self, data_dir, model_category, transform=None):
        self.samples = []
        self.transform = transform
        self.model_category = model_category
        
        for cls_name, label in [("real", 0), ("fake", 1)]:
            path = os.path.join(data_dir, cls_name)
            if os.path.exists(path):
                # ê° ì¼€ì´ìŠ¤ë³„ 33ê°œ ì˜ìƒ ì „ìˆ˜ ì¡°ì‚¬
                files = sorted([f for f in os.listdir(path) if f.lower().endswith('.mp4')])[:33]
                for f in files:
                    self.samples.append((os.path.join(path, f), label))

    def __len__(self): return len(self.samples)

    def __getitem__(self, idx):
        v_path, label = self.samples[idx]
        cap = cv2.VideoCapture(v_path)
        frames = []
        
        try:
            if self.model_category == "spatial":
                total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                cap.set(cv2.CAP_PROP_POS_FRAMES, total // 2)
                ret, frame = cap.read()
                if not ret: frame = np.zeros((224, 224, 3), dtype=np.uint8)
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                if self.transform: frame = self.transform(frame)
                cap.release()
                return frame, label
            else:
                for _ in range(SEQ_LEN):
                    ret, frame = cap.read()
                    if not ret: frame = np.zeros((224, 224, 3), dtype=np.uint8)
                    else: frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    if self.transform: frame = self.transform(frame)
                    frames.append(frame)
                cap.release()
                frames = torch.stack(frames).permute(1, 0, 2, 3) # (C, T, H, W)
                return frames, label
        except Exception as e:
            cap.release()
            # ì—ëŸ¬ ë°œìƒ ì‹œ ë¹ˆ í…ì„œ ë°˜í™˜
            return torch.zeros((3, 224, 224)) if self.model_category == "spatial" else torch.zeros((3, 16, 224, 224)), label

# ==========================================
# ğŸ—ï¸ 3. ëª¨ë¸ ë¡œë“œ ë° ìµœì í™”
# ==========================================
def load_model_safely(m_file):
    parts = m_file.replace('.pth', '').split('_')
    m_cat = parts[1] 
    m_name = parts[2]
    
    if m_cat == "spatial":
        if m_name == "xception": model = timm.create_model('xception', num_classes=2)
        elif m_name == "convnext": model = timm.create_model('convnext_tiny', num_classes=2)
        elif m_name == "swin": model = timm.create_model('swin_tiny_patch4_window7_224', num_classes=2)
    elif m_cat == "temporal":
        if m_name == "r3d": model = models.video.r3d_18(num_classes=2)
        elif m_name == "r2plus1d": model = models.video.r2plus1d_18(num_classes=2)
        elif m_name == "videomae":
            model = VideoMAEForVideoClassification.from_pretrained("MCG-NJU/videomae-base", num_labels=2, ignore_mismatched_sizes=True)
            
    model.load_state_dict(torch.load(os.path.join(MODEL_DIR, m_file), map_location=DEVICE))
    return model.to(DEVICE).eval(), m_cat

# ==========================================
# ğŸš€ 4. 288ê°œ ì‹¤í—˜ ì „ìˆ˜ ì¡°ì‚¬ ë£¨í”„
# ==========================================
def run():
    model_files = sorted([f for f in os.listdir(MODEL_DIR) if f.startswith('model_') and f.endswith('.pth')])
    print(f"ğŸ” ì´ {len(model_files)}ê°œì˜ ëª¨ë¸ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    
    final_results = []

    for m_file in model_files:
        print(f"\nğŸ“Š í‰ê°€ ì¤‘: {m_file}")
        model, m_cat = load_model_safely(m_file)
        
        # 4070 SUPERì˜ ì„±ëŠ¥ì„ í™œìš©í•˜ê¸° ìœ„í•´ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ 16ìœ¼ë¡œ ì˜¬ë ¸ìŠµë‹ˆë‹¤.
        batch_size = 16 
        size = 112 if any(x in m_file for x in ["r3d", "r2plus1d"]) else 224
        transform = transforms.Compose([
            transforms.ToPILImage(), transforms.Resize((size, size)),
            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

        for domain in DOMAINS:
            for case in CASES:
                test_path = os.path.join(BASE_DIR, domain, case)
                # ìœˆë„ìš° í™˜ê²½ì´ë¯€ë¡œ num_workersëŠ” 0~2 ì‚¬ì´ê°€ ì•ˆì „í•©ë‹ˆë‹¤.
                dataset = RobustnessEvalDataset(test_path, m_cat, transform)
                if len(dataset) == 0: continue
                
                loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)
                y_true, y_probs = [], []

                with torch.no_grad():
                    for inputs, labels in loader:
                        inputs = inputs.to(DEVICE)
                        if "videomae" in m_file:
                            inputs = inputs.permute(0, 2, 1, 3, 4)
                            outputs = model(pixel_values=inputs).logits
                        else:
                            outputs = model(inputs)
                        
                        probs = torch.softmax(outputs, dim=1)[:, 1]
                        y_true.extend(labels.numpy())
                        y_probs.extend(probs.cpu().numpy())

                acc = accuracy_score(y_true, np.array(y_probs) > 0.5)
                try: auc = roc_auc_score(y_true, y_probs)
                except: auc = 0.5
                
                final_results.append({
                    "Model": m_file, "Domain": domain, "Case": case,
                    "Accuracy": acc, "AUC": auc
                })
                print(f"   [{domain}/{case}] ACC: {acc:.2f} | AUC: {auc:.2f}")

    # ìµœì¢… ì—‘ì…€ ë° CSV ì €ì¥
    df = pd.DataFrame(final_results)
    df.to_excel("Final_Robustness_Analysis_288.xlsx", index=False)
    print("\nâœ¨ 288ê°œ ì‹¤í—˜ ì „ìˆ˜ ì¡°ì‚¬ ì™„ë£Œ! ì—‘ì…€ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    run()